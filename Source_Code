** FLIPKART SENTIMENT ANALYSIS USING PYTHON
I have learning more about python and machine learning libraries to brush up my data skills, Today I have taken a kaggle dataset of FLIPKART Reviews to perform Sentiment Analysis.

**Data Import and Initial Exploration:

#Import the dataset and inspect its structure.
Check for any missing values in the dataset.

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

data = pd.read_csv("https://raw.githubusercontent.com/amankharwal/Website-data/master/flipkart_reviews.csv")
print(data.head())

Output: 
                                        Product_name                                             Review  Rating
0  Lenovo Ideapad Gaming 3 Ryzen 5 Hexa Core 5600...  Best under 60k Great performanceI got it for a...       5
1  Lenovo Ideapad Gaming 3 Ryzen 5 Hexa Core 5600...                                 Good perfomence...       5
2  Lenovo Ideapad Gaming 3 Ryzen 5 Hexa Core 5600...  Great performance but usually it has also that...       5
3  DELL Inspiron Athlon Dual Core 3050U - (4 GB/2...           My wife is so happy and best product ðŸ‘ŒðŸ»ðŸ˜˜       5
4  DELL Inspiron Athlon Dual Core 3050U - (4 GB/2...  Light weight laptop with new amazing features,...       5

#Check for any missing values in the dataset.
print(data.isnull().sum())
Output: 
>>> print(data.isnull().sum())
Product_name    0
Review          0
Rating          0
dtype: int64

** Data Preprocessing:
#Clean the text data by removing noise such as URLs, punctuation, and stopwords.
import nltk
import re
nltk.download('stopwords')
stemmer = nltk.SnowballStemmer("english")
from nltk.corpus import stopwords
import string
stopword=set(stopwords.words('english'))

def clean(text):
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text = [word for word in text.split(' ') if word not in stopword]
    text=" ".join(text)
    text = [stemmer.stem(word) for word in text.split(' ')]
    text=" ".join(text)
    return text
data["Review"] = data["Review"].apply(clean)

**Visualization:
#Visualize the distribution of ratings using a pie chart.

ratings = data["Rating"].value_counts()
numbers = ratings.index
quantity = ratings.values

import plotly.express as px
figure = px.pie(data, 
             values=quantity, 
             names=numbers,hole = 0.5)
figure.show()
#Using wordcloud to visualize the most used words in review column

text = " ".join(i for i in data.Review)
stopwords = set(STOPWORDS)
wordcloud = WordCloud(stopwords=stopwords, 
                      background_color="white").generate(text)
plt.figure( figsize=(15,10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

**Sentiment Analysis:

#Utilize the VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis 

nltk.download('vader_lexicon')
sentiments = SentimentIntensityAnalyzer()
data["Positive"] = [sentiments.polarity_scores(i)["pos"] for i in data["Review"]]
data["Negative"] = [sentiments.polarity_scores(i)["neg"] for i in data["Review"]]
data["Neutral"] = [sentiments.polarity_scores(i)["neu"] for i in data["Review"]]
data = data[["Review", "Positive", "Negative", "Neutral"]]

>>> print(data.head())
                                              Review  Positive  Negative  Neutral
0  best  great performancei got around  backup bi...     0.395     0.101    0.504
1                                        good perfom     0.744     0.000    0.256
2  great perform usual also game laptop issu batt...     0.277     0.000    0.723
3                        wife happi best product ðŸ‘ŒðŸ»ðŸ˜˜     0.512     0.000    0.488
4  light weight laptop new amaz featur batteri li...     0.000     0.000    1.000

#TO see how reviewers thoughts on Products on service of Flipkart

x = sum(data["Positive"])
y = sum(data["Negative"])
z = sum(data["Neutral"])

def sentiment_score(a, b, c):
    if (a>b) and (a>c):
        print("Positive ðŸ˜Š ")
    elif (b>a) and (b>c):
        print("Negative ðŸ˜  ")
    else:
        print("Neutral ðŸ™‚ ")
sentiment_score(x, y, z)
Output: >>> sentiment_score(x, y, z)
Neutral ðŸ™‚

print("Positive: ", x)
print("Negative: ", y)
print("Neutral: ", z)

Output:  
>>> print("Positive: ", x)
Positive:  923.553
>>> print("Negative: ", y)
Negative:  96.775
>>> print("Neutral: ", z)
Neutral:  1283.688
>>>

**Conclusion: After the analysis we found the reviwers are on Neutral Side, and looking on scores We can say people are satisfied by FLIPKART services and products.
